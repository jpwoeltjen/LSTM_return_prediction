Train on 1660 samples, validate on 338 samples
Epoch 1/100
1s - loss: 0.3762 - val_loss: 0.4890
Epoch 2/100
0s - loss: 0.3675 - val_loss: 0.1764
Epoch 3/100
0s - loss: 0.2880 - val_loss: 0.0885
Epoch 4/100
0s - loss: 0.1507 - val_loss: 0.1846
Epoch 5/100
0s - loss: 0.1745 - val_loss: 0.1051
Epoch 6/100
0s - loss: 0.1653 - val_loss: 0.0871
Epoch 7/100
0s - loss: 0.1251 - val_loss: 0.1102
Epoch 8/100
0s - loss: 0.1309 - val_loss: 0.0809
Epoch 9/100
0s - loss: 0.1259 - val_loss: 0.0789
Epoch 10/100
0s - loss: 0.1161 - val_loss: 0.0865
Epoch 11/100
0s - loss: 0.1221 - val_loss: 0.0776
Epoch 12/100
0s - loss: 0.1167 - val_loss: 0.0758
Epoch 13/100
0s - loss: 0.1105 - val_loss: 0.0776
Epoch 14/100
0s - loss: 0.1098 - val_loss: 0.0769
Epoch 15/100
0s - loss: 0.1115 - val_loss: 0.0756
Epoch 16/100
0s - loss: 0.1153 - val_loss: 0.0765
Epoch 17/100
0s - loss: 0.1090 - val_loss: 0.0780
Epoch 18/100
0s - loss: 0.1110 - val_loss: 0.0765
Epoch 19/100
0s - loss: 0.1067 - val_loss: 0.0758
Epoch 20/100
0s - loss: 0.1088 - val_loss: 0.0758
Epoch 21/100
0s - loss: 0.1049 - val_loss: 0.0760
Epoch 22/100
0s - loss: 0.1079 - val_loss: 0.0757
Epoch 23/100
0s - loss: 0.1056 - val_loss: 0.0756
Epoch 24/100
0s - loss: 0.1057 - val_loss: 0.0754
Epoch 25/100
0s - loss: 0.1013 - val_loss: 0.0764
Epoch 26/100
0s - loss: 0.1016 - val_loss: 0.0765
Epoch 27/100
0s - loss: 0.1069 - val_loss: 0.0756
Epoch 28/100
0s - loss: 0.1006 - val_loss: 0.0755
Epoch 29/100
0s - loss: 0.1023 - val_loss: 0.0756
Epoch 30/100
0s - loss: 0.0978 - val_loss: 0.0755
Epoch 31/100
0s - loss: 0.0980 - val_loss: 0.0756
Epoch 32/100
0s - loss: 0.0960 - val_loss: 0.0759
Epoch 33/100
0s - loss: 0.1028 - val_loss: 0.0756
Epoch 34/100
0s - loss: 0.1014 - val_loss: 0.0756
Epoch 35/100
0s - loss: 0.1007 - val_loss: 0.0755
Epoch 36/100
0s - loss: 0.0993 - val_loss: 0.0756
Epoch 37/100
0s - loss: 0.0993 - val_loss: 0.0757
Epoch 38/100
0s - loss: 0.0977 - val_loss: 0.0756
Epoch 39/100
0s - loss: 0.0999 - val_loss: 0.0756
Epoch 40/100
0s - loss: 0.0963 - val_loss: 0.0755
Epoch 41/100
0s - loss: 0.0973 - val_loss: 0.0757
Epoch 42/100
0s - loss: 0.0965 - val_loss: 0.0756
Epoch 43/100
0s - loss: 0.0963 - val_loss: 0.0757
Epoch 44/100
0s - loss: 0.0957 - val_loss: 0.0756
Epoch 45/100
0s - loss: 0.0912 - val_loss: 0.0757
Epoch 46/100
0s - loss: 0.0941 - val_loss: 0.0756
Epoch 47/100
0s - loss: 0.0939 - val_loss: 0.0756
Epoch 48/100
0s - loss: 0.0953 - val_loss: 0.0756
Epoch 49/100
0s - loss: 0.0929 - val_loss: 0.0758
Epoch 50/100
0s - loss: 0.0959 - val_loss: 0.0756
Epoch 51/100
0s - loss: 0.0917 - val_loss: 0.0755
Epoch 52/100
0s - loss: 0.0908 - val_loss: 0.0756
Epoch 53/100
0s - loss: 0.0910 - val_loss: 0.0758
Epoch 54/100
0s - loss: 0.0912 - val_loss: 0.0758
Epoch 55/100
0s - loss: 0.0882 - val_loss: 0.0755
Epoch 56/100
0s - loss: 0.0936 - val_loss: 0.0756
Epoch 57/100
0s - loss: 0.0914 - val_loss: 0.0758
Epoch 58/100
0s - loss: 0.0900 - val_loss: 0.0755
Epoch 59/100
1s - loss: 0.0889 - val_loss: 0.0755
Epoch 60/100
0s - loss: 0.0912 - val_loss: 0.0755
Epoch 61/100
0s - loss: 0.0908 - val_loss: 0.0756
Epoch 62/100
0s - loss: 0.0908 - val_loss: 0.0756
Epoch 63/100
0s - loss: 0.0882 - val_loss: 0.0756
Epoch 64/100
0s - loss: 0.0916 - val_loss: 0.0758
Epoch 65/100
0s - loss: 0.0859 - val_loss: 0.0757
Epoch 66/100
0s - loss: 0.0893 - val_loss: 0.0757
Epoch 67/100
0s - loss: 0.0866 - val_loss: 0.0756
Epoch 68/100
0s - loss: 0.0873 - val_loss: 0.0756
Epoch 69/100
0s - loss: 0.0896 - val_loss: 0.0756
Epoch 70/100
0s - loss: 0.0889 - val_loss: 0.0756
Epoch 71/100
0s - loss: 0.0857 - val_loss: 0.0756
Epoch 72/100
0s - loss: 0.0885 - val_loss: 0.0756
Epoch 73/100
0s - loss: 0.0888 - val_loss: 0.0756
Epoch 74/100
0s - loss: 0.0870 - val_loss: 0.0756
Epoch 75/100
0s - loss: 0.0854 - val_loss: 0.0756
Epoch 76/100
0s - loss: 0.0871 - val_loss: 0.0755
Epoch 77/100
0s - loss: 0.0874 - val_loss: 0.0755
Epoch 78/100
0s - loss: 0.0870 - val_loss: 0.0755
Epoch 79/100
0s - loss: 0.0861 - val_loss: 0.0755
Epoch 80/100
0s - loss: 0.0830 - val_loss: 0.0755
Epoch 81/100
0s - loss: 0.0868 - val_loss: 0.0755
Epoch 82/100
0s - loss: 0.0865 - val_loss: 0.0756
Epoch 83/100
0s - loss: 0.0875 - val_loss: 0.0755
Epoch 84/100
0s - loss: 0.0873 - val_loss: 0.0755
Epoch 85/100
0s - loss: 0.0864 - val_loss: 0.0755
Epoch 86/100
0s - loss: 0.0888 - val_loss: 0.0755
Epoch 87/100
0s - loss: 0.0841 - val_loss: 0.0755
Epoch 88/100
0s - loss: 0.0861 - val_loss: 0.0755
Epoch 89/100
0s - loss: 0.0825 - val_loss: 0.0755
Epoch 90/100
0s - loss: 0.0840 - val_loss: 0.0757
Epoch 91/100
0s - loss: 0.0851 - val_loss: 0.0755
Epoch 92/100
0s - loss: 0.0845 - val_loss: 0.0756
Epoch 93/100
0s - loss: 0.0842 - val_loss: 0.0756
Epoch 94/100
0s - loss: 0.0835 - val_loss: 0.0755
Epoch 95/100
1s - loss: 0.0840 - val_loss: 0.0755
Epoch 96/100
0s - loss: 0.0843 - val_loss: 0.0757
Epoch 97/100
0s - loss: 0.0817 - val_loss: 0.0755
Epoch 98/100
0s - loss: 0.0865 - val_loss: 0.0755
Epoch 99/100
0s - loss: 0.0839 - val_loss: 0.0755
Epoch 100/100
0s - loss: 0.0831 - val_loss: 0.0755
1) Validation RMSE: 0.006
Train on 1660 samples, validate on 338 samples
Epoch 1/100
1s - loss: 0.3088 - val_loss: 0.1047
Epoch 2/100
0s - loss: 0.2057 - val_loss: 0.0771
Epoch 3/100
0s - loss: 0.1535 - val_loss: 0.0839
Epoch 4/100
0s - loss: 0.1317 - val_loss: 0.0980
Epoch 5/100
0s - loss: 0.1287 - val_loss: 0.0981
Epoch 6/100
0s - loss: 0.1279 - val_loss: 0.0867
Epoch 7/100
0s - loss: 0.1310 - val_loss: 0.0767
Epoch 8/100
0s - loss: 0.1193 - val_loss: 0.0756
Epoch 9/100
0s - loss: 0.1174 - val_loss: 0.0756
Epoch 10/100
0s - loss: 0.1135 - val_loss: 0.0767
Epoch 11/100
0s - loss: 0.1197 - val_loss: 0.0777
Epoch 12/100
0s - loss: 0.1105 - val_loss: 0.0760
Epoch 13/100
0s - loss: 0.1134 - val_loss: 0.0756
Epoch 14/100
0s - loss: 0.1058 - val_loss: 0.0754
Epoch 15/100
0s - loss: 0.1087 - val_loss: 0.0765
Epoch 16/100
0s - loss: 0.1052 - val_loss: 0.0754
Epoch 17/100
0s - loss: 0.1067 - val_loss: 0.0759
Epoch 18/100
0s - loss: 0.1109 - val_loss: 0.0758
Epoch 19/100
0s - loss: 0.1062 - val_loss: 0.0757
Epoch 20/100
0s - loss: 0.1038 - val_loss: 0.0755
Epoch 21/100
0s - loss: 0.1045 - val_loss: 0.0758
Epoch 22/100
0s - loss: 0.1043 - val_loss: 0.0777
Epoch 23/100
0s - loss: 0.1031 - val_loss: 0.0771
Epoch 24/100
0s - loss: 0.0999 - val_loss: 0.0768
Epoch 25/100
0s - loss: 0.1015 - val_loss: 0.0757
Epoch 26/100
0s - loss: 0.1000 - val_loss: 0.0760
Epoch 27/100
0s - loss: 0.0985 - val_loss: 0.0761
Epoch 28/100
0s - loss: 0.0968 - val_loss: 0.0757
Epoch 29/100
0s - loss: 0.0976 - val_loss: 0.0759
Epoch 30/100
0s - loss: 0.0993 - val_loss: 0.0757
Epoch 31/100
0s - loss: 0.0964 - val_loss: 0.0755
Epoch 32/100
0s - loss: 0.0953 - val_loss: 0.0755
Epoch 33/100
0s - loss: 0.0975 - val_loss: 0.0754
Epoch 34/100
1s - loss: 0.0928 - val_loss: 0.0754
Epoch 35/100
1s - loss: 0.0948 - val_loss: 0.0754
Epoch 36/100
1s - loss: 0.0955 - val_loss: 0.0754
Epoch 37/100
1s - loss: 0.0939 - val_loss: 0.0754
Epoch 38/100
1s - loss: 0.0934 - val_loss: 0.0754
Epoch 39/100
1s - loss: 0.0905 - val_loss: 0.0755
Epoch 40/100
0s - loss: 0.0935 - val_loss: 0.0757
Epoch 41/100
1s - loss: 0.0908 - val_loss: 0.0756
Epoch 42/100
1s - loss: 0.0895 - val_loss: 0.0756
Epoch 43/100
0s - loss: 0.0935 - val_loss: 0.0756
Epoch 44/100
0s - loss: 0.0908 - val_loss: 0.0756
Epoch 45/100
0s - loss: 0.0931 - val_loss: 0.0756
Epoch 46/100
0s - loss: 0.0904 - val_loss: 0.0756
Epoch 47/100
0s - loss: 0.0930 - val_loss: 0.0755
Epoch 48/100
0s - loss: 0.0905 - val_loss: 0.0755
Epoch 49/100
0s - loss: 0.0912 - val_loss: 0.0755
Epoch 50/100
0s - loss: 0.0890 - val_loss: 0.0755
Epoch 51/100
0s - loss: 0.0885 - val_loss: 0.0754
Epoch 52/100
0s - loss: 0.0893 - val_loss: 0.0755
Epoch 53/100
0s - loss: 0.0877 - val_loss: 0.0755
Epoch 54/100
0s - loss: 0.0881 - val_loss: 0.0755
Epoch 55/100
1s - loss: 0.0884 - val_loss: 0.0755
Epoch 56/100
0s - loss: 0.0864 - val_loss: 0.0755
Epoch 57/100
1s - loss: 0.0874 - val_loss: 0.0756
Epoch 58/100
1s - loss: 0.0858 - val_loss: 0.0755
Epoch 59/100
1s - loss: 0.0867 - val_loss: 0.0755
Epoch 60/100
0s - loss: 0.0852 - val_loss: 0.0754
Epoch 61/100
0s - loss: 0.0852 - val_loss: 0.0754
Epoch 62/100
0s - loss: 0.0859 - val_loss: 0.0754
Epoch 63/100
0s - loss: 0.0836 - val_loss: 0.0754
Epoch 64/100
0s - loss: 0.0834 - val_loss: 0.0755
Epoch 65/100
0s - loss: 0.0856 - val_loss: 0.0755
Epoch 66/100
0s - loss: 0.0843 - val_loss: 0.0754
Epoch 67/100
0s - loss: 0.0843 - val_loss: 0.0755
Epoch 68/100
0s - loss: 0.0834 - val_loss: 0.0755
Epoch 69/100
0s - loss: 0.0841 - val_loss: 0.0758
Epoch 70/100
0s - loss: 0.0838 - val_loss: 0.0755
Epoch 71/100
0s - loss: 0.0835 - val_loss: 0.0755
Epoch 72/100
0s - loss: 0.0816 - val_loss: 0.0755
Epoch 73/100
0s - loss: 0.0819 - val_loss: 0.0755
Epoch 74/100
0s - loss: 0.0844 - val_loss: 0.0756
Epoch 75/100
0s - loss: 0.0837 - val_loss: 0.0756
Epoch 76/100
0s - loss: 0.0834 - val_loss: 0.0757
Epoch 77/100
0s - loss: 0.0838 - val_loss: 0.0756
Epoch 78/100
0s - loss: 0.0838 - val_loss: 0.0755
Epoch 79/100
0s - loss: 0.0821 - val_loss: 0.0756
Epoch 80/100
0s - loss: 0.0849 - val_loss: 0.0755
Epoch 81/100
0s - loss: 0.0824 - val_loss: 0.0756
Epoch 82/100
0s - loss: 0.0808 - val_loss: 0.0755
Epoch 83/100
0s - loss: 0.0824 - val_loss: 0.0755
Epoch 84/100
0s - loss: 0.0833 - val_loss: 0.0755
Epoch 85/100
0s - loss: 0.0825 - val_loss: 0.0756
Epoch 86/100
0s - loss: 0.0794 - val_loss: 0.0756
Epoch 87/100
0s - loss: 0.0812 - val_loss: 0.0755
Epoch 88/100
0s - loss: 0.0819 - val_loss: 0.0755
Epoch 89/100
0s - loss: 0.0815 - val_loss: 0.0755
Epoch 90/100
0s - loss: 0.0826 - val_loss: 0.0755
Epoch 91/100
0s - loss: 0.0814 - val_loss: 0.0756
Epoch 92/100
0s - loss: 0.0809 - val_loss: 0.0755
Epoch 93/100
0s - loss: 0.0811 - val_loss: 0.0755
Epoch 94/100
0s - loss: 0.0812 - val_loss: 0.0755
Epoch 95/100
0s - loss: 0.0821 - val_loss: 0.0755
Epoch 96/100
0s - loss: 0.0801 - val_loss: 0.0755
Epoch 97/100
0s - loss: 0.0792 - val_loss: 0.0755
Epoch 98/100
0s - loss: 0.0795 - val_loss: 0.0755
Epoch 99/100
0s - loss: 0.0807 - val_loss: 0.0755
Epoch 100/100
0s - loss: 0.0794 - val_loss: 0.0755
2) Validation RMSE: 0.006
Train on 1660 samples, validate on 338 samples
Epoch 1/100
1s - loss: 1.3136 - val_loss: 1.0043
Epoch 2/100
0s - loss: 1.1470 - val_loss: 1.0219
Epoch 3/100
0s - loss: 1.0855 - val_loss: 1.0731
Epoch 4/100
0s - loss: 1.0598 - val_loss: 1.0443
Epoch 5/100
0s - loss: 1.0920 - val_loss: 0.9981
Epoch 6/100
0s - loss: 1.0528 - val_loss: 1.0050
Epoch 7/100
0s - loss: 1.0403 - val_loss: 1.0156
Epoch 8/100
0s - loss: 1.0538 - val_loss: 1.0042
Epoch 9/100
0s - loss: 1.0347 - val_loss: 0.9988
Epoch 10/100
0s - loss: 1.0763 - val_loss: 1.0040
Epoch 11/100
1s - loss: 1.0461 - val_loss: 1.0049
Epoch 12/100
0s - loss: 1.0336 - val_loss: 0.9994
Epoch 13/100
0s - loss: 1.0392 - val_loss: 1.0012
Epoch 14/100
0s - loss: 1.0389 - val_loss: 1.0008
Epoch 15/100
0s - loss: 1.0419 - val_loss: 0.9997
Epoch 16/100
0s - loss: 1.0327 - val_loss: 1.0000
Epoch 17/100
0s - loss: 1.0457 - val_loss: 0.9996
Epoch 18/100
0s - loss: 1.0360 - val_loss: 0.9998
Epoch 19/100
0s - loss: 1.0216 - val_loss: 0.9993
Epoch 20/100
0s - loss: 1.0301 - val_loss: 0.9992
Epoch 21/100
0s - loss: 1.0195 - val_loss: 0.9995
Epoch 22/100
0s - loss: 1.0170 - val_loss: 0.9998
Epoch 23/100
0s - loss: 1.0347 - val_loss: 0.9999
Epoch 24/100
0s - loss: 1.0305 - val_loss: 1.0000
Epoch 25/100
0s - loss: 1.0328 - val_loss: 1.0001
Epoch 26/100
0s - loss: 1.0447 - val_loss: 1.0000
Epoch 27/100
0s - loss: 1.0234 - val_loss: 1.0000
Epoch 28/100
0s - loss: 1.0265 - val_loss: 1.0002
Epoch 29/100
0s - loss: 1.0256 - val_loss: 1.0005
Epoch 30/100
0s - loss: 1.0336 - val_loss: 1.0005
Epoch 31/100
0s - loss: 1.0216 - val_loss: 1.0000
Epoch 32/100
0s - loss: 1.0296 - val_loss: 0.9996
Epoch 33/100
0s - loss: 1.0294 - val_loss: 0.9993
Epoch 34/100
0s - loss: 1.0266 - val_loss: 0.9991
Epoch 35/100
0s - loss: 1.0257 - val_loss: 0.9994
Epoch 36/100
0s - loss: 1.0285 - val_loss: 0.9998
Epoch 37/100
0s - loss: 1.0252 - val_loss: 1.0001
Epoch 38/100
0s - loss: 1.0299 - val_loss: 1.0005
Epoch 39/100
0s - loss: 1.0092 - val_loss: 1.0008
Epoch 40/100
0s - loss: 1.0138 - val_loss: 1.0007
Epoch 41/100
0s - loss: 1.0136 - val_loss: 1.0009
Epoch 42/100
0s - loss: 1.0206 - val_loss: 1.0007
Epoch 43/100
0s - loss: 1.0196 - val_loss: 1.0008
Epoch 44/100
0s - loss: 1.0147 - val_loss: 1.0005
Epoch 45/100
0s - loss: 1.0135 - val_loss: 1.0005
Epoch 46/100
0s - loss: 1.0192 - val_loss: 1.0009
Epoch 47/100
0s - loss: 1.0069 - val_loss: 1.0008
Epoch 48/100
0s - loss: 1.0087 - val_loss: 1.0005
Epoch 49/100
0s - loss: 1.0144 - val_loss: 0.9998
Epoch 50/100
0s - loss: 1.0215 - val_loss: 0.9997
Epoch 51/100
0s - loss: 1.0289 - val_loss: 0.9999
Epoch 52/100
1s - loss: 1.0136 - val_loss: 1.0000
Epoch 53/100
0s - loss: 1.0171 - val_loss: 1.0003
Epoch 54/100
0s - loss: 1.0127 - val_loss: 1.0006
Epoch 55/100
0s - loss: 1.0123 - val_loss: 1.0006
Epoch 56/100
0s - loss: 1.0175 - val_loss: 1.0007
Epoch 57/100
0s - loss: 1.0257 - val_loss: 1.0008
Epoch 58/100
1s - loss: 1.0027 - val_loss: 1.0007
Epoch 59/100
1s - loss: 1.0128 - val_loss: 1.0003
Epoch 60/100
1s - loss: 1.0119 - val_loss: 1.0001
Epoch 61/100
0s - loss: 1.0187 - val_loss: 1.0000
Epoch 62/100
0s - loss: 1.0126 - val_loss: 1.0000
Epoch 63/100
0s - loss: 1.0166 - val_loss: 1.0001
Epoch 64/100
0s - loss: 1.0208 - val_loss: 1.0004
Epoch 65/100
0s - loss: 1.0190 - val_loss: 1.0003
Epoch 66/100
0s - loss: 1.0150 - val_loss: 1.0004
Epoch 67/100
0s - loss: 1.0187 - val_loss: 1.0005
Epoch 68/100
0s - loss: 1.0096 - val_loss: 1.0006
Epoch 69/100
0s - loss: 1.0098 - val_loss: 1.0008
Epoch 70/100
0s - loss: 1.0115 - val_loss: 1.0010
Epoch 71/100
0s - loss: 1.0081 - val_loss: 1.0009
Epoch 72/100
0s - loss: 1.0097 - val_loss: 1.0009
Epoch 73/100
0s - loss: 1.0115 - val_loss: 1.0010
Epoch 74/100
0s - loss: 1.0069 - val_loss: 1.0015
Epoch 75/100
0s - loss: 1.0061 - val_loss: 1.0014
Epoch 76/100
0s - loss: 1.0072 - val_loss: 1.0014
Epoch 77/100
0s - loss: 1.0035 - val_loss: 1.0014
Epoch 78/100
0s - loss: 1.0156 - val_loss: 1.0015
Epoch 79/100
0s - loss: 1.0001 - val_loss: 1.0015
Epoch 80/100
0s - loss: 1.0062 - val_loss: 1.0013
Epoch 81/100
0s - loss: 1.0074 - val_loss: 1.0013
Epoch 82/100
0s - loss: 1.0159 - val_loss: 1.0013
Epoch 83/100
0s - loss: 1.0108 - val_loss: 1.0012
Epoch 84/100
0s - loss: 1.0096 - val_loss: 1.0013
Epoch 85/100
0s - loss: 1.0071 - val_loss: 1.0013
Epoch 86/100
0s - loss: 1.0103 - val_loss: 1.0013
Epoch 87/100
0s - loss: 1.0121 - val_loss: 1.0012
Epoch 88/100
0s - loss: 1.0045 - val_loss: 1.0011
Epoch 89/100
0s - loss: 1.0053 - val_loss: 1.0013
Epoch 90/100
0s - loss: 1.0082 - val_loss: 1.0013
Epoch 91/100
0s - loss: 1.0115 - val_loss: 1.0014
Epoch 92/100
0s - loss: 1.0055 - val_loss: 1.0015
Epoch 93/100
0s - loss: 1.0040 - val_loss: 1.0016
Epoch 94/100
0s - loss: 1.0117 - val_loss: 1.0017
Epoch 95/100
0s - loss: 1.0056 - val_loss: 1.0018
Epoch 96/100
0s - loss: 1.0104 - val_loss: 1.0016
Epoch 97/100
0s - loss: 1.0071 - val_loss: 1.0016
Epoch 98/100
0s - loss: 1.0003 - val_loss: 1.0016
Epoch 99/100
0s - loss: 1.0048 - val_loss: 1.0015
Epoch 100/100
0s - loss: 1.0074 - val_loss: 1.0016
1) Validation RMSE: 0.006
Train on 1660 samples, validate on 338 samples
Epoch 1/100
1s - loss: 1.2666 - val_loss: 1.2898
Epoch 2/100
0s - loss: 1.2110 - val_loss: 1.0929
Epoch 3/100
0s - loss: 1.1607 - val_loss: 0.9952
Epoch 4/100
0s - loss: 1.0841 - val_loss: 1.0345
Epoch 5/100
0s - loss: 1.0336 - val_loss: 1.0404
Epoch 6/100
0s - loss: 1.0645 - val_loss: 0.9992
Epoch 7/100
0s - loss: 1.0484 - val_loss: 1.0022
Epoch 8/100
0s - loss: 1.0359 - val_loss: 1.0100
Epoch 9/100
0s - loss: 1.0534 - val_loss: 1.0020
Epoch 10/100
0s - loss: 1.0401 - val_loss: 1.0002
Epoch 11/100
0s - loss: 1.0687 - val_loss: 1.0009
Epoch 12/100
0s - loss: 1.0269 - val_loss: 0.9998
Epoch 13/100
0s - loss: 1.0395 - val_loss: 0.9995
Epoch 14/100
0s - loss: 1.0386 - val_loss: 0.9990
Epoch 15/100
0s - loss: 1.0447 - val_loss: 0.9989
Epoch 16/100
0s - loss: 1.0460 - val_loss: 0.9989
Epoch 17/100
0s - loss: 1.0221 - val_loss: 0.9992
Epoch 18/100
0s - loss: 1.0284 - val_loss: 0.9994
Epoch 19/100
0s - loss: 1.0365 - val_loss: 0.9995
Epoch 20/100
0s - loss: 1.0304 - val_loss: 0.9995
Epoch 21/100
0s - loss: 1.0260 - val_loss: 0.9996
Epoch 22/100
0s - loss: 1.0235 - val_loss: 0.9997
Epoch 23/100
0s - loss: 1.0246 - val_loss: 0.9993
Epoch 24/100
0s - loss: 1.0240 - val_loss: 0.9993
Epoch 25/100
0s - loss: 1.0214 - val_loss: 1.0003
Epoch 26/100
0s - loss: 1.0264 - val_loss: 0.9993
Epoch 27/100
0s - loss: 1.0258 - val_loss: 0.9998
Epoch 28/100
0s - loss: 1.0256 - val_loss: 0.9991
Epoch 29/100
0s - loss: 1.0174 - val_loss: 0.9996
Epoch 30/100
0s - loss: 1.0279 - val_loss: 1.0002
Epoch 31/100
0s - loss: 1.0251 - val_loss: 1.0001
Epoch 32/100
0s - loss: 1.0163 - val_loss: 1.0002
Epoch 33/100
0s - loss: 1.0312 - val_loss: 0.9999
Epoch 34/100
0s - loss: 1.0215 - val_loss: 1.0001
Epoch 35/100
0s - loss: 1.0200 - val_loss: 1.0000
Epoch 36/100
0s - loss: 1.0204 - val_loss: 1.0003
Epoch 37/100
0s - loss: 1.0177 - val_loss: 1.0004
Epoch 38/100
0s - loss: 1.0243 - val_loss: 1.0001
Epoch 39/100
0s - loss: 1.0213 - val_loss: 1.0001
Epoch 40/100
0s - loss: 1.0189 - val_loss: 1.0000
Epoch 41/100
0s - loss: 1.0070 - val_loss: 1.0000
Epoch 42/100
0s - loss: 1.0050 - val_loss: 1.0004
Epoch 43/100
0s - loss: 1.0102 - val_loss: 1.0008
Epoch 44/100
0s - loss: 1.0293 - val_loss: 1.0011
Epoch 45/100
0s - loss: 1.0120 - val_loss: 1.0015
Epoch 46/100
0s - loss: 1.0234 - val_loss: 1.0015
Epoch 47/100
0s - loss: 1.0077 - val_loss: 1.0015
Epoch 48/100
0s - loss: 1.0076 - val_loss: 1.0011
Epoch 49/100
0s - loss: 1.0078 - val_loss: 1.0010
Epoch 50/100
0s - loss: 1.0191 - val_loss: 1.0013
Epoch 51/100
0s - loss: 1.0169 - val_loss: 1.0007
Epoch 52/100
0s - loss: 1.0213 - val_loss: 1.0006
Epoch 53/100
0s - loss: 1.0169 - val_loss: 1.0004
Epoch 54/100
0s - loss: 1.0176 - val_loss: 1.0003
Epoch 55/100
0s - loss: 1.0162 - val_loss: 1.0005
Epoch 56/100
0s - loss: 1.0067 - val_loss: 1.0006
Epoch 57/100
0s - loss: 1.0092 - val_loss: 1.0004
Epoch 58/100
0s - loss: 1.0119 - val_loss: 1.0008
Epoch 59/100
0s - loss: 1.0203 - val_loss: 1.0005
Epoch 60/100
0s - loss: 1.0091 - val_loss: 1.0003
Epoch 61/100
0s - loss: 1.0113 - val_loss: 1.0003
Epoch 62/100
0s - loss: 1.0222 - val_loss: 1.0004
Epoch 63/100
0s - loss: 1.0063 - val_loss: 1.0004
Epoch 64/100
0s - loss: 1.0184 - val_loss: 1.0003
Epoch 65/100
0s - loss: 1.0121 - val_loss: 1.0004
Epoch 66/100
0s - loss: 1.0218 - val_loss: 1.0004
Epoch 67/100
0s - loss: 1.0161 - val_loss: 1.0005
Epoch 68/100
0s - loss: 1.0144 - val_loss: 1.0008
Epoch 69/100
0s - loss: 1.0161 - val_loss: 1.0011
Epoch 70/100
0s - loss: 1.0150 - val_loss: 1.0014
Epoch 71/100
0s - loss: 1.0122 - val_loss: 1.0011
Epoch 72/100
0s - loss: 1.0098 - val_loss: 1.0011
Epoch 73/100
0s - loss: 1.0125 - val_loss: 1.0010
Epoch 74/100
0s - loss: 1.0051 - val_loss: 1.0008
Epoch 75/100
0s - loss: 1.0160 - val_loss: 1.0007
Epoch 76/100
0s - loss: 1.0124 - val_loss: 1.0008
Epoch 77/100
0s - loss: 1.0069 - val_loss: 1.0010
Epoch 78/100
0s - loss: 1.0073 - val_loss: 1.0012
Epoch 79/100
0s - loss: 1.0046 - val_loss: 1.0012
Epoch 80/100
0s - loss: 1.0129 - val_loss: 1.0013
Epoch 81/100
0s - loss: 1.0118 - val_loss: 1.0013
Epoch 82/100
0s - loss: 1.0151 - val_loss: 1.0012
Epoch 83/100
0s - loss: 1.0152 - val_loss: 1.0012
Epoch 84/100
0s - loss: 1.0078 - val_loss: 1.0014
Epoch 85/100
0s - loss: 1.0056 - val_loss: 1.0012
Epoch 86/100
0s - loss: 1.0070 - val_loss: 1.0014
Epoch 87/100
0s - loss: 1.0041 - val_loss: 1.0011
Epoch 88/100
0s - loss: 1.0098 - val_loss: 1.0010
Epoch 89/100
0s - loss: 1.0064 - val_loss: 1.0010
Epoch 90/100
0s - loss: 1.0093 - val_loss: 1.0010
Epoch 91/100
0s - loss: 1.0128 - val_loss: 1.0011
Epoch 92/100
0s - loss: 1.0019 - val_loss: 1.0012
Epoch 93/100
0s - loss: 1.0129 - val_loss: 1.0013
Epoch 94/100
0s - loss: 1.0174 - val_loss: 1.0014
Epoch 95/100
0s - loss: 1.0077 - val_loss: 1.0013
Epoch 96/100
0s - loss: 1.0105 - val_loss: 1.0013
Epoch 97/100
0s - loss: 1.0087 - val_loss: 1.0013
Epoch 98/100
0s - loss: 1.0070 - val_loss: 1.0014
Epoch 99/100
0s - loss: 1.0040 - val_loss: 1.0016
Epoch 100/100
0s - loss: 1.0072 - val_loss: 1.0015
2) Validation RMSE: 0.006
 Selecting model [2 lags][100 epochs][512 batch][5 neurons][l1 0.00,l2 0.00][l1 0.00,l2 0.00][l1 0.00,l2 0.00][0.0010 lr][0.0010 lrd][0.20 do][normalize] based on smallest mean of validation RMSE. Out of: dict_keys(['[2 lags][100 epochs][512 batch][5 neurons][l1 0.00,l2 0.00][l1 0.00,l2 0.00][l1 0.00,l2 0.00][0.0010 lr][0.0010 lrd][0.20 do][normalize]', '[2 lags][100 epochs][512 batch][5 neurons][l1 0.00,l2 0.00][l1 0.00,l2 0.00][l1 0.00,l2 0.00][0.0010 lr][0.0010 lrd][0.20 do][standardize]'])
       [2 lags][100 epochs][512 batch][5 neurons][l1 0.00,l2 0.00][l1 0.00,l2 0.00][l1 0.00,l2 0.00][0.0010 lr][0.0010 lrd][0.20 do][normalize]  \
count                                           2.000000                                                                                          
mean                                            0.006297                                                                                          
std                                             0.000001                                                                                          
min                                             0.006296                                                                                          
25%                                             0.006296                                                                                          
50%                                             0.006297                                                                                          
75%                                             0.006297                                                                                          
max                                             0.006298                                                                                          

       [2 lags][100 epochs][512 batch][5 neurons][l1 0.00,l2 0.00][l1 0.00,l2 0.00][l1 0.00,l2 0.00][0.0010 lr][0.0010 lrd][0.20 do][standardize]  
count                                       2.000000e+00                                                                                           
mean                                        6.304612e-03                                                                                           
std                                         2.968382e-07                                                                                           
min                                         6.304402e-03                                                                                           
25%                                         6.304507e-03                                                                                           
50%                                         6.304612e-03                                                                                           
75%                                         6.304717e-03                                                                                           
max                                         6.304822e-03                                                                                           
::::::::FOR MODEL: [2 lags][100 epochs][512 batch][5 neurons][l1 0.00,l2 0.00][l1 0.00,l2 0.00][l1 0.00,l2 0.00][0.0010 lr][0.0010 lrd][0.20 do][normalize]:::::::
Percent correct 0.00_sigma: 49.7858319605 %
percentage of periods betting up 0.00_sigma : 30.4118616145 %; percentage of periods betting down: 0.00_sigma  69.5881383855 %; percentage of periods staying out of the market: 0.00_sigma  0.0 %
There were 1186 total trades for 0.00_sigma.
The annualised_sharpe for 0.00_sigma. is: -0.04.
The CAGR for 0.00_sigma. is: -0.84 percent.
Percent correct 0.25_sigma: 49.92 %
percentage of periods betting up 0.25_sigma : 22.4052718287 %; percentage of periods betting down: 0.25_sigma  59.9670510708 %; percentage of periods staying out of the market: 0.25_sigma  17.6276771005 %
There were 1588 total trades for 0.25_sigma.
The annualised_sharpe for 0.25_sigma. is: 0.01.
The CAGR for 0.25_sigma. is: -0.28 percent.
Percent correct 0.50_sigma: 50.5940594059 %
percentage of periods betting up 0.50_sigma : 16.2108731466 %; percentage of periods betting down: 0.50_sigma  50.3459637562 %; percentage of periods staying out of the market: 0.50_sigma  33.4431630972 %
There were 1732 total trades for 0.50_sigma.
The annualised_sharpe for 0.50_sigma. is: 0.22.
The CAGR for 0.50_sigma. is: 1.49 percent.
Percent correct 1.00_sigma: 51.3392857143 %
percentage of periods betting up 1.00_sigma : 6.78747940692 %; percentage of periods betting down: 1.00_sigma  30.1153212521 %; percentage of periods staying out of the market: 1.00_sigma  63.097199341 %
There were 1416 total trades for 1.00_sigma.
The annualised_sharpe for 1.00_sigma. is: 0.17.
The CAGR for 1.00_sigma. is: 0.86 percent.
Percent correct 2.00_sigma: 53.6458333333 %
percentage of periods betting up 2.00_sigma : 0.593080724876 %; percentage of periods betting down: 2.00_sigma  5.73311367381 %; percentage of periods staying out of the market: 2.00_sigma  93.6738056013 %
There were 342 total trades for 2.00_sigma.
The annualised_sharpe for 2.00_sigma. is: 0.04.
The CAGR for 2.00_sigma. is: 0.06 percent.
::::::::FOR MODEL: [2 lags][100 epochs][512 batch][5 neurons][l1 0.00,l2 0.00][l1 0.00,l2 0.00][l1 0.00,l2 0.00][0.0010 lr][0.0010 lrd][0.20 do][standardize]:::::::
Percent correct 0.00_sigma: 49.9176276771 %
percentage of periods betting up 0.00_sigma : 26.8863261944 %; percentage of periods betting down: 0.00_sigma  73.1136738056 %; percentage of periods staying out of the market: 0.00_sigma  0.0 %
There were 1062 total trades for 0.00_sigma.
The annualised_sharpe for 0.00_sigma. is: 0.11.
The CAGR for 0.00_sigma. is: 0.61 percent.
Percent correct 0.25_sigma: 50.019432569 %
percentage of periods betting up 0.25_sigma : 19.6046128501 %; percentage of periods betting down: 0.25_sigma  65.1729818781 %; percentage of periods staying out of the market: 0.25_sigma  15.2224052718 %
There were 1433 total trades for 0.25_sigma.
The annualised_sharpe for 0.25_sigma. is: 0.09.
The CAGR for 0.25_sigma. is: 0.37 percent.
Percent correct 0.50_sigma: 49.6634615385 %
percentage of periods betting up 0.50_sigma : 13.5090609555 %; percentage of periods betting down: 0.50_sigma  55.0247116969 %; percentage of periods staying out of the market: 0.50_sigma  31.4662273476 %
There were 1618 total trades for 0.50_sigma.
The annualised_sharpe for 0.50_sigma. is: -0.04.
The CAGR for 0.50_sigma. is: -0.69 percent.
Percent correct 1.00_sigma: 50.7269789984 %
percentage of periods betting up 1.00_sigma : 5.79901153213 %; percentage of periods betting down: 1.00_sigma  34.9917627677 %; percentage of periods staying out of the market: 1.00_sigma  59.2092257002 %
There were 1394 total trades for 1.00_sigma.
The annualised_sharpe for 1.00_sigma. is: 0.21.
The CAGR for 1.00_sigma. is: 1.13 percent.
Percent correct 2.00_sigma: 51.4403292181 %
percentage of periods betting up 2.00_sigma : 0.428336079077 %; percentage of periods betting down: 2.00_sigma  7.57825370675 %; percentage of periods staying out of the market: 2.00_sigma  91.9934102142 %
There were 409 total trades for 2.00_sigma.
The annualised_sharpe for 2.00_sigma. is: -0.16.
The CAGR for 2.00_sigma. is: -0.47 percent.
